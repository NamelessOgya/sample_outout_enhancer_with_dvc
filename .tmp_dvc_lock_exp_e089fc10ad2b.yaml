schema: '2.0'
stages:
  evaluate:
    cmd: python -m run.evaluate
    deps:
    - path: data/
      hash: md5
      md5: 26afe518d513bb3b3da61c889b5a4ce2.dir
      size: 1158
      nfiles: 1
    - path: src/sample_judge/prompt
      hash: md5
      md5: 1427533ff7947135278d60a7918c5668.dir
      size: 385
      nfiles: 2
    - path: src/sample_judge/rule_base_judge
      hash: md5
      md5: d751713988987e9331980363e24189ce.dir
      size: 0
      nfiles: 0
    outs:
    - path: result/result.csv
      hash: md5
      md5: f5b5c9a18e78458d1a2fdd35d4096e10
      size: 5684
  rulebase_evaluate@count_text_length:
    cmd: python -m run.rulebase_evaluate --rulebase_func_name count_text_length 
      --submit_file_name submit
    deps:
    - path: data/submit/submit.csv
      hash: md5
      md5: faac4d81aab978d5a1a76dad1ab0b0b9
      size: 1158
    - path: run/rulebase_evaluate.py
      hash: md5
      md5: 9a137379c5cb13f8d9beb401829bdd4d
      size: 1602
    - path: src/judge/rulebase_funcs/count_text_length.py
      hash: md5
      md5: 055b0c892221991b62284da516344de5
      size: 356
    outs:
    - path: data/result/rulebase_submit_count_text_length.json
      hash: md5
      md5: 5afa9720ea705444361965285f7d1fe9
      size: 1283
  rulebase_evaluate@check_megu_in_text:
    cmd: python -m run.rulebase_evaluate --rulebase_func_name check_megu_in_text
      --submit_file_name submit
    deps:
    - path: data/submit/submit.csv
      hash: md5
      md5: faac4d81aab978d5a1a76dad1ab0b0b9
      size: 1158
    - path: run/rulebase_evaluate.py
      hash: md5
      md5: 9a137379c5cb13f8d9beb401829bdd4d
      size: 1602
    - path: src/judge/rulebase_funcs/check_megu_in_text.py
      hash: md5
      md5: a05c349a92ce22b233956445f5ab403b
      size: 380
    outs:
    - path: data/result/rulebase_submit_check_megu_in_text.json
      hash: md5
      md5: 15cce71818b45e3045330a857b985f43
      size: 1283
  llm_evaluate@check_if_category_in_text:
    cmd: python -m run.llm_evaluate --prompt_name check_if_category_in_text 
      --submit_file_name submit
    deps:
    - path: data/submit/submit.csv
      hash: md5
      md5: faac4d81aab978d5a1a76dad1ab0b0b9
      size: 1158
    - path: run/llm_evaluate.py
      hash: md5
      md5: 6b78857f7ea7b4637dc31a8f5bb36e7e
      size: 1682
    - path: src/judge/prompt/check_if_category_in_text.txt
      hash: md5
      md5: 2d6d66c9c29a288f2114d7cbd0a9a078
      size: 183
    outs:
    - path: data/result/llm_submit_check_if_category_in_text.json
      hash: md5
      md5: 2a9bbe09bc300ba07623cd8aeb4b2e7f
      size: 1376
  llm_evaluate@check_if_gakunen_in_text:
    cmd: python -m run.llm_evaluate --prompt_name check_if_gakunen_in_text 
      --submit_file_name submit
    deps:
    - path: data/submit/submit.csv
      hash: md5
      md5: faac4d81aab978d5a1a76dad1ab0b0b9
      size: 1158
    - path: run/llm_evaluate.py
      hash: md5
      md5: 6b78857f7ea7b4637dc31a8f5bb36e7e
      size: 1682
    - path: src/judge/prompt/check_if_gakunen_in_text.txt
      hash: md5
      md5: b2c196a574b01de1914f29010f3f4fc6
      size: 184
      isexec: true
    outs:
    - path: data/result/llm_submit_check_if_gakunen_in_text.json
      hash: md5
      md5: 2a9bbe09bc300ba07623cd8aeb4b2e7f
      size: 1376
  make_dashboard:
    cmd: poetry run python -m run.make_dashboard
    deps:
    - path: data/result/
      hash: md5
      md5: 9b069ca872c52e7fe51da6dca514ce81.dir
      size: 5318
      nfiles: 4
    - path: run/make_dashboard.py
      hash: md5
      md5: 7e4899d6793020fbb81bb63bbde8b2ba
      size: 2282
    outs:
    - path: data/dashboard/mikoto_run_ids.csv
      hash: md5
      md5: c28448e9a2efe3d34d028475c62615ca
      size: 818
    - path: data/dashboard/scores.csv
      hash: md5
      md5: bbd478a02300e3db394645446c2cb2af
      size: 806
  llm_generate:
    cmd: poetry run python -m run.llm_generate --generate_target_name data 
      --prompt_name set_idol_discription
    deps:
    - path: data/generate_target/data.csv
      hash: md5
      md5: fbf274e04fdb7adc0b2fafbf175e220f
      size: 97
    - path: run/llm_generate.py
      hash: md5
      md5: 0a56088818378a8750201e2f891bb7fe
      size: 1851
    - path: src/generate/prompt/set_idol_discription.txt
      hash: md5
      md5: 9fa318a5f6130535fb3cc444e79b7166
      size: 145
    params:
      params.yaml:
        generate:
          generate_data_name: data
          generate_prompt_name: set_idol_discription
          model_config:
            inference_prompt: inference_prompt.txt
            inference_model: gpt-3.5-turbo
    outs:
    - path: data/submit/data_set_idol_discription.csv
      hash: md5
      md5: fa2efd153139f9dae93ec1cbace03b3e
      size: 1321
